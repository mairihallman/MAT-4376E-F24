{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation by Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FiveThreeEight methodology:\n",
    "- cap sample sizes at 5000\n",
    "- if sample size isn't reported, use median sample size of polls from that polster (if no other info, use median sample size of all other polls\n",
    "- sample size weighting - square root of poll's sample size / square root for median sample size for group\n",
    "\n",
    "See `notes-p1.md` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>pollster</th>\n",
       "      <th>grade</th>\n",
       "      <th>samplesize</th>\n",
       "      <th>population</th>\n",
       "      <th>rawpoll_clinton</th>\n",
       "      <th>rawpoll_trump</th>\n",
       "      <th>rawpoll_johnson</th>\n",
       "      <th>rawpoll_mcmullin</th>\n",
       "      <th>adjpoll_clinton</th>\n",
       "      <th>adjpoll_trump</th>\n",
       "      <th>adjpoll_johnson</th>\n",
       "      <th>adjpoll_mcmullin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>A+</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>47.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.20163</td>\n",
       "      <td>41.72430</td>\n",
       "      <td>4.626221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>Google Consumer Surveys</td>\n",
       "      <td>B</td>\n",
       "      <td>26574.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>38.03</td>\n",
       "      <td>35.69</td>\n",
       "      <td>5.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.34557</td>\n",
       "      <td>41.21439</td>\n",
       "      <td>5.175792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Ipsos</td>\n",
       "      <td>A-</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>42.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.02638</td>\n",
       "      <td>38.81620</td>\n",
       "      <td>6.844734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>YouGov</td>\n",
       "      <td>B</td>\n",
       "      <td>3677.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>45.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.65676</td>\n",
       "      <td>40.92004</td>\n",
       "      <td>6.069454</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>Gravis Marketing</td>\n",
       "      <td>B-</td>\n",
       "      <td>16639.0</td>\n",
       "      <td>rv</td>\n",
       "      <td>47.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.84089</td>\n",
       "      <td>42.33184</td>\n",
       "      <td>3.726098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2016-09-16</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>Ipsos</td>\n",
       "      <td>A-</td>\n",
       "      <td>452.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>46.54</td>\n",
       "      <td>40.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.47852</td>\n",
       "      <td>40.48017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>2016-08-07</td>\n",
       "      <td>Marquette University</td>\n",
       "      <td>A</td>\n",
       "      <td>683.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>47.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.74781</td>\n",
       "      <td>39.07778</td>\n",
       "      <td>4.705020</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>Utah</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>Google Consumer Surveys</td>\n",
       "      <td>B</td>\n",
       "      <td>286.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>21.33</td>\n",
       "      <td>35.05</td>\n",
       "      <td>9.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.65200</td>\n",
       "      <td>40.57738</td>\n",
       "      <td>9.705791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>2016-10-21</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>Ipsos</td>\n",
       "      <td>A-</td>\n",
       "      <td>446.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>46.46</td>\n",
       "      <td>37.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.12949</td>\n",
       "      <td>37.10720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>EPIC-MRA</td>\n",
       "      <td>A-</td>\n",
       "      <td>600.0</td>\n",
       "      <td>lv</td>\n",
       "      <td>43.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.14966</td>\n",
       "      <td>42.05508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4208 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          state  startdate    enddate                  pollster grade  \\\n",
       "0          U.S. 2016-11-03 2016-11-06  ABC News/Washington Post    A+   \n",
       "1          U.S. 2016-11-01 2016-11-07   Google Consumer Surveys     B   \n",
       "2          U.S. 2016-11-02 2016-11-06                     Ipsos    A-   \n",
       "3          U.S. 2016-11-04 2016-11-07                    YouGov     B   \n",
       "4          U.S. 2016-11-03 2016-11-06          Gravis Marketing    B-   \n",
       "...         ...        ...        ...                       ...   ...   \n",
       "4203   Virginia 2016-09-16 2016-09-22                     Ipsos    A-   \n",
       "4204  Wisconsin 2016-08-04 2016-08-07      Marquette University     A   \n",
       "4205       Utah 2016-11-01 2016-11-07   Google Consumer Surveys     B   \n",
       "4206     Oregon 2016-10-21 2016-11-02                     Ipsos    A-   \n",
       "4207   Michigan 2016-01-23 2016-01-26                  EPIC-MRA    A-   \n",
       "\n",
       "      samplesize population  rawpoll_clinton  rawpoll_trump  rawpoll_johnson  \\\n",
       "0         2220.0         lv            47.00          43.00             4.00   \n",
       "1        26574.0         lv            38.03          35.69             5.46   \n",
       "2         2195.0         lv            42.00          39.00             6.00   \n",
       "3         3677.0         lv            45.00          41.00             5.00   \n",
       "4        16639.0         rv            47.00          43.00             3.00   \n",
       "...          ...        ...              ...            ...              ...   \n",
       "4203       452.0         lv            46.54          40.04              NaN   \n",
       "4204       683.0         lv            47.00          34.00             9.00   \n",
       "4205       286.0         lv            21.33          35.05             9.99   \n",
       "4206       446.0         lv            46.46          37.41              NaN   \n",
       "4207       600.0         lv            43.00          41.00              NaN   \n",
       "\n",
       "      rawpoll_mcmullin  adjpoll_clinton  adjpoll_trump  adjpoll_johnson  \\\n",
       "0                  NaN         45.20163       41.72430         4.626221   \n",
       "1                  NaN         43.34557       41.21439         5.175792   \n",
       "2                  NaN         42.02638       38.81620         6.844734   \n",
       "3                  NaN         45.65676       40.92004         6.069454   \n",
       "4                  NaN         46.84089       42.33184         3.726098   \n",
       "...                ...              ...            ...              ...   \n",
       "4203               NaN         46.47852       40.48017              NaN   \n",
       "4204               NaN         48.74781       39.07778         4.705020   \n",
       "4205               NaN         26.65200       40.57738         9.705791   \n",
       "4206               NaN         45.12949       37.10720              NaN   \n",
       "4207               NaN         42.14966       42.05508              NaN   \n",
       "\n",
       "      adjpoll_mcmullin  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "...                ...  \n",
       "4203               NaN  \n",
       "4204               NaN  \n",
       "4205               NaN  \n",
       "4206               NaN  \n",
       "4207               NaN  \n",
       "\n",
       "[4208 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data-p1/polls_us_election_2016.csv\")\n",
    "\n",
    "df['startdate'] = pd.to_datetime(df['startdate'])\n",
    "df['enddate'] = pd.to_datetime(df['enddate'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "A-    1085\n",
       "B     1011\n",
       "C-     693\n",
       "C+     329\n",
       "B+     204\n",
       "A      159\n",
       "B-     142\n",
       "A+      84\n",
       "C       58\n",
       "D       14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_order = [\"F\",\"D\",\"D+\",\"C-\",\"C\",\"C+\",\"B-\",\"B\",\"B+\",\"A-\",\"A\",\"A+\"] # still included missing grades\n",
    "df['grade'] = pd.Categorical(df['grade'], categories=grade_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "population\n",
       "lv    3727\n",
       "rv     418\n",
       "v       42\n",
       "a       21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"population\"].value_counts() # will probably just use likely voters, but keeping all for now in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                  0\n",
       "startdate              0\n",
       "enddate                0\n",
       "pollster               0\n",
       "grade                429\n",
       "samplesize             1\n",
       "population             0\n",
       "rawpoll_clinton        0\n",
       "rawpoll_trump          0\n",
       "rawpoll_johnson     1409\n",
       "rawpoll_mcmullin    4178\n",
       "adjpoll_clinton        0\n",
       "adjpoll_trump          0\n",
       "adjpoll_johnson     1409\n",
       "adjpoll_mcmullin    4178\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"rawpoll_johnson\",\"rawpoll_mcmullin\",\"adjpoll_johnson\",\"adjpoll_mcmullin\"]) # just looking at Clinton and Trump for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollster_medians = df.groupby('pollster')['samplesize'].median()\n",
    "overall_median = float(df['samplesize'].median())\n",
    "\n",
    "# imputation for sample size based on FiveThirtyEight methodology\n",
    "def fill_na_with_median(row):\n",
    "\n",
    "    if pd.isna(row['samplesize']):\n",
    "        pollster_median = pollster_medians[row['pollster']]\n",
    "        \n",
    "        if pd.isna(pollster_median):\n",
    "            return overall_median\n",
    "        \n",
    "        return pollster_median\n",
    "    \n",
    "    return row['samplesize']\n",
    "\n",
    "df['samplesize'] = df.apply(fill_na_with_median, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['samplesizeadj'] = df['samplesize'].apply(lambda x: min(x, 5000)) # cap sample sizes at 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('data-p1/polls-clean.h5', key='df', mode='w', format='t')\n",
    "df.to_csv('data-p1/polls_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mairi\\AppData\\Local\\Temp\\ipykernel_23412\\3131936701.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  agg_df = df.groupby(['pollster', 'state', 'population', 'day']).apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollster</th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>day</th>\n",
       "      <th>weighted_clinton</th>\n",
       "      <th>weighted_trump</th>\n",
       "      <th>samplesize_total</th>\n",
       "      <th>c-minus-t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>lv</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>lv</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>lv</td>\n",
       "      <td>2016-09-29</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>lv</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>63.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC News/Washington Post</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20292</th>\n",
       "      <td>icitizen</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20293</th>\n",
       "      <td>icitizen</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-09-16</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20294</th>\n",
       "      <td>icitizen</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20295</th>\n",
       "      <td>icitizen</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-09-18</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20296</th>\n",
       "      <td>icitizen</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>rv</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20297 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pollster     state population        day  \\\n",
       "0      ABC News/Washington Post  Maryland         lv 2016-09-27   \n",
       "1      ABC News/Washington Post  Maryland         lv 2016-09-28   \n",
       "2      ABC News/Washington Post  Maryland         lv 2016-09-29   \n",
       "3      ABC News/Washington Post  Maryland         lv 2016-09-30   \n",
       "4      ABC News/Washington Post  Maryland         rv 2016-03-30   \n",
       "...                         ...       ...        ...        ...   \n",
       "20292                  icitizen      U.S.         rv 2016-09-15   \n",
       "20293                  icitizen      U.S.         rv 2016-09-16   \n",
       "20294                  icitizen      U.S.         rv 2016-09-17   \n",
       "20295                  icitizen      U.S.         rv 2016-09-18   \n",
       "20296                  icitizen      U.S.         rv 2016-09-19   \n",
       "\n",
       "       weighted_clinton  weighted_trump  samplesize_total  c-minus-t  \n",
       "0                  63.0            27.0             706.0       36.0  \n",
       "1                  63.0            27.0             706.0       36.0  \n",
       "2                  63.0            27.0             706.0       36.0  \n",
       "3                  63.0            27.0             706.0       36.0  \n",
       "4                  63.0            28.0             752.0       35.0  \n",
       "...                 ...             ...               ...        ...  \n",
       "20292              42.0            37.0            1000.0        5.0  \n",
       "20293              42.0            37.0            1000.0        5.0  \n",
       "20294              42.0            37.0            1000.0        5.0  \n",
       "20295              42.0            37.0            1000.0        5.0  \n",
       "20296              42.0            37.0            1000.0        5.0  \n",
       "\n",
       "[20297 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_to_individual_days(df):\n",
    "    expanded_rows = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        day_range = pd.date_range(start=row['startdate'], end=row['enddate'])\n",
    "        \n",
    "        for day in day_range:\n",
    "            expanded_row = row.copy()\n",
    "            expanded_row['day'] = day\n",
    "            expanded_rows.append(expanded_row)\n",
    "    \n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# formula from FiveThirtyEight\n",
    "def weighted_average(group, value_column):\n",
    "    sqrt_sample_sizes = group['samplesizeadj'] ** 0.5 \n",
    "    median_sqrt_sample_size = group['samplesizeadj'].median() ** 0.5\n",
    "    weights = sqrt_sample_sizes / median_sqrt_sample_size\n",
    "    return (group[value_column] * weights).sum() / weights.sum()\n",
    "\n",
    "def aggregate_by_day(df):\n",
    "    agg_df = df.groupby(['pollster', 'state', 'population', 'day']).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'weighted_clinton': weighted_average(x, 'rawpoll_clinton'),\n",
    "            'weighted_trump': weighted_average(x, 'rawpoll_trump'),\n",
    "            'samplesize_total': x['samplesizeadj'].sum()\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    agg_df[\"c-minus-t\"] = agg_df[\"weighted_clinton\"] - agg_df[\"weighted_trump\"]\n",
    "    return agg_df\n",
    "\n",
    "expanded_df = split_to_individual_days(df)\n",
    "\n",
    "df_agg = aggregate_by_day(expanded_df)\n",
    "\n",
    "df_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.to_hdf('data-p1/agg_polls_by_day.h5', key='df', mode='w', format='t') # h5 format to preserve data types (categorical, datetime, etc)\n",
    "df_agg.to_csv('data-p1/agg_polls_by_day.csv', index=False) # csv format in case anyone wants to use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
